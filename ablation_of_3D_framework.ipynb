{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIvx-8iMokKl"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import subprocess\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "905sFSMlv7ug"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkKr2S91zMx1"
      },
      "outputs": [],
      "source": [
        "%cd /content/gdrive/MyDrive/\n",
        "!pip install nibabel\n",
        "!pip install glob\n",
        "!pip install quantus\n",
        "!pip install monai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPRchmoP2B2f"
      },
      "outputs": [],
      "source": [
        "#Author: Michail Mamalakis\n",
        "#Version: 0.1\n",
        "#Licence:\n",
        "#email:mm2703@cam.ac.uk\n",
        "\n",
        "# name of weights store of main segmentation\n",
        "import nibabel as nib\n",
        "from scipy import ndimage\n",
        "import numpy as np\n",
        "import glob\n",
        "import skimage.transform as skTrans\n",
        "from scipy.ndimage import rotate\n",
        "import quantus\n",
        "\n",
        "d=184\n",
        "w=184\n",
        "h=64\n",
        "c=1\n",
        "format_file='nii'\n",
        "\n",
        "\n",
        "def read_nifti_file(filepath):\n",
        "  \"\"\"\tRead and load volume\"\"\"\n",
        "  # Read file\n",
        "  if format_file=='nii':\n",
        "    scan = nib.load(filepath)\n",
        "  else:\n",
        "    scan = nib.load(filepath('gifti', 'ascii.gii'))\n",
        "  # Get raw data\n",
        "  scan = scan.get_fdata()\n",
        "  return scan\n",
        "\n",
        "\n",
        "def normalize(volume):\n",
        "  \"\"\"Normalize the volume\"\"\"\n",
        "  min = np.min(volume)\n",
        "  max = np.max(volume)\n",
        "  volume[volume < min] = min\n",
        "  volume[volume > max] = max\n",
        "  volume = (volume - min) / (max - min)\n",
        "  volume = volume.astype(\"float32\")\n",
        "  return volume\n",
        "\n",
        "\n",
        "def resize_volume(img,zoom='off'):\n",
        "  \"\"\"Resize across z-axis\"\"\"\n",
        "  # Set the desired depth\n",
        "  print(img.shape)\n",
        "  if img.shape[1]<img.shape[2]:\n",
        "    img=np.transpose(img,(1,2,0,3))\n",
        "  elif img.shape[1]>img.shape[2]:\n",
        "    img=np.transpose(img,(2,0,1,3))\n",
        "  else:\n",
        "    print('img is ok')\n",
        "  if zoom!='off':\n",
        "    desired_depth = d\n",
        "    desired_width = w\n",
        "    desired_height = h\n",
        "    # Get current depth\n",
        "    if len(img.shape)==4:\n",
        "      current_depth = img.shape[0]\n",
        "      current_width = img.shape[1]\n",
        "      current_height = img.shape[2]\n",
        "    else:\n",
        "      current_depth = img.shape[0]\n",
        "      current_width = img.shape[1]\n",
        "      current_height = img.shape[2]\n",
        "\t  # Compute depth factor\n",
        "    depth = current_depth / desired_depth\n",
        "    width = current_width / desired_width\n",
        "    height = current_height / desired_height\n",
        "    depth_factor = 1 / depth\n",
        "    width_factor = 1 / width\n",
        "    height_factor = 1 / height\n",
        "\t  # Rotate\n",
        "\t  #print(img.shape)\n",
        "    img = ndimage.rotate(img, 90, reshape=False)\n",
        "\t  # Resize across z-axis\n",
        "    print(img.shape,width_factor,height_factor,depth_factor)\n",
        "    if len(img.shape)==4:\n",
        "      if img.shape[1]==img.shape[2]:\n",
        "    #    img=np.transpose(img, (1, 2, 0, 3))\n",
        "        print(img.shape)\n",
        "      img = ndimage.zoom(img, (depth_factor, height_factor, width_factor,1), order=1)\n",
        "    else:\n",
        "      if img.shape[1]==img.shape[2]:\n",
        "    #   img=np.transpose(img, (1, 2, 0))\n",
        "        img = ndimage.zoom(img, (depth_factor, height_factor, width_factor), order=1)\n",
        "  else:\n",
        "    #img=np.transpose(img, (2,1,0,3))\n",
        "    img=skTrans.resize(img,(d,w,h,c),order=1,preserve_range=True)\n",
        "  return img\n",
        "\n",
        "def save(store,volume):\n",
        "  imgnthree1=nib.Nifti1Image(volume, affine=np.eye(4))\n",
        "  imgnthree1.header.set_data_dtype(np.uint32)\n",
        "  nib.save(imgnthree1,store)\n",
        "\n",
        "def process_scan(path,store,case_ex,comb=6,zoom='off',list_given='none',d=184,w=184,h=184,c=1):\n",
        "  \"\"\"Read and resize volume\"\"\"\n",
        "  # Read scan\n",
        "  volume_tot=np.zeros((d,w,h,c))\n",
        "  list2=[]\n",
        "  list1=sorted((glob.glob(path+'*'+case_ex)))\n",
        "  sum=0.1\n",
        "  if comb==2:\n",
        "    if list_given=='none':\n",
        "      list2=[0.85,0.5,0.1]\n",
        "    else:\n",
        "      list2=list_given\n",
        "    sum=1.45\n",
        "  else:\n",
        "    for x in range(1,comb):\n",
        "      list2.append((comb-x)/comb)\n",
        "      sum=sum+((comb-x)/comb)\n",
        "    list2.append(0.1)\n",
        "  #if listg!=[]:\n",
        "  #list2=[0.8,0.4]\n",
        "  #sum=1.20\n",
        "  print(list1,list2)\n",
        "  for i in range(comb):\n",
        "    volume = read_nifti_file(list1[i])\n",
        "    # Normalize\n",
        "    volume = normalize(volume)\n",
        "\t\t# Resize width, height and depth\n",
        "    #volume = resize_volume(volume,zoom)\n",
        "    #volume =np.resize(volume ,[64,184,184,1])\n",
        "    volume_tot=volume_tot+list2[i]*volume\n",
        "  volume_tot=volume_tot/sum\n",
        "  save(store+'total_'+case_ex,volume_tot)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#case_ex='GradCam.nii.gz'\n",
        "#store='XAI_MHL/Shap/R/R_PCS_1'\n",
        "#path='XAI_MHL/Shap/R/PCS/'\n",
        "#comb=6\n",
        "#zoom='off'\n",
        "#process_scan(path,store,case_ex,comb,zoom)\n"
      ],
      "metadata": {
        "id": "-NwO5RGf0PrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "id": "7EoqkiivYrva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "from typing import Any, Union, Optional\n",
        "from typing import Tuple, Dict\n",
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import sys\n",
        "import subprocess\n",
        "from monai.networks.layers.factories import Conv, Norm, Pool\n",
        "from monai.networks.layers.utils import get_pool_layer\n",
        "from monai.utils import ensure_tuple_rep\n",
        "from monai.utils.module import look_up_option\n",
        "\n",
        "device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def get_inplanes():\n",
        "    return [64, 128, 256, 512]\n",
        "\n",
        "\n",
        "def get_avgpool():\n",
        "    return [0, 1, (1, 1), (1, 1, 1)]\n",
        "\n",
        "\n",
        "class ResNetBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_planes: int,\n",
        "        planes: int,\n",
        "        spatial_dims: int = 3,\n",
        "        stride: int = 1,\n",
        "        inplace: bool = True,\n",
        "        downsample: Union[nn.Module,partial] = None,\n",
        "    ) -> None:\n",
        "         super().__init__()\n",
        "\n",
        "         conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
        "         norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n",
        "\n",
        "         self.conv1 = conv_type(in_planes, planes, kernel_size=3, padding=1, stride=stride, bias=False)\n",
        "         self.bn1 = norm_type(planes)\n",
        "         self.relu = nn.ReLU(inplace=inplace)\n",
        "         self.conv2 = conv_type(planes, planes, kernel_size=3, padding=1, bias=False)\n",
        "         self.bn2 = norm_type(planes)\n",
        "         self.downsample = downsample\n",
        "         self.stride = stride\n",
        "         self.relu2 = nn.ReLU(inplace=inplace)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        residual = x\n",
        "\n",
        "        out: torch.Tensor = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu2(out)\n",
        "        return out\n",
        "\n",
        "class ResNetBottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_planes: int,\n",
        "        planes: int,\n",
        "        spatial_dims: int = 3,\n",
        "        stride: int = 1,\n",
        "        inplace:bool=True,\n",
        "        downsample: Union[nn.Module,partial] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            in_planes: number of input channels.\n",
        "            planes: number of output channels (taking expansion into account).\n",
        "            spatial_dims: number of spatial dimensions of the input image.\n",
        "            stride: stride to use for second conv layer.\n",
        "            downsample: which downsample layer to use.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
        "        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n",
        "\n",
        "        self.conv1 = conv_type(in_planes, planes, kernel_size=1, bias=False)\n",
        "\n",
        "        self.bn1 = norm_type(planes)\n",
        "        self.conv2 = conv_type(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = norm_type(planes)\n",
        "        self.conv3 = conv_type(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = norm_type(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=inplace)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.relu2 = nn.ReLU(inplace=inplace)\n",
        "        self.relu3 = nn.ReLU(inplace=inplace)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        residual = x\n",
        "\n",
        "        out: torch.Tensor = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu3(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "     def __init__(\n",
        "        self,\n",
        "        block: Union[type[Union[ResNetBlock ,ResNetBottleneck]] ,str],\n",
        "        layers: list[int],\n",
        "        block_inplanes: list[int],\n",
        "        spatial_dims: int = 3,\n",
        "        n_input_channels: int = 3,\n",
        "        conv1_t_size: Union[tuple[int] , int] = 7,\n",
        "        conv1_t_stride: Union[tuple[int] , int] = 1,\n",
        "        no_max_pool: bool = False,\n",
        "        shortcut_type: str = \"B\",\n",
        "        widen_factor: float = 1.0,\n",
        "        num_classes: int = 400,\n",
        "        feed_forward: bool = True,\n",
        "        inplace: bool=True,\n",
        "        bias_downsample: bool = True,  # for backwards compatibility (also see PR #5477)\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        if isinstance(block, str):\n",
        "            if block == \"basic\":\n",
        "                block = ResNetBlock\n",
        "            elif block == \"bottleneck\":\n",
        "                block = ResNetBottleneck\n",
        "            else:\n",
        "                raise ValueError(\"Unknown block '%s', use basic or bottleneck\" % block)\n",
        "\n",
        "        conv_type: type[Union[nn.Conv1d , nn.Conv2d , nn.Conv3d]] = Conv[Conv.CONV, spatial_dims]\n",
        "        norm_type: type[Union[nn.BatchNorm1d , nn.BatchNorm2d , nn.BatchNorm3d]] = Norm[Norm.BATCH, spatial_dims]\n",
        "        pool_type: type[Union[nn.MaxPool1d , nn.MaxPool2d , nn.MaxPool3d]] = Pool[Pool.MAX, spatial_dims]\n",
        "        avgp_type: type[Union[nn.AdaptiveAvgPool1d , nn.AdaptiveAvgPool2d , nn.AdaptiveAvgPool3d]] = Pool[\n",
        "            Pool.ADAPTIVEAVG, spatial_dims\n",
        "        ]\n",
        "\n",
        "        block_avgpool = get_avgpool()\n",
        "        block_inplanes = [int(x * widen_factor) for x in block_inplanes]\n",
        "        self.inplace=inplace\n",
        "        self.in_planes = block_inplanes[0]\n",
        "        self.no_max_pool = no_max_pool\n",
        "        self.bias_downsample = bias_downsample\n",
        "\n",
        "        conv1_kernel_size = ensure_tuple_rep(conv1_t_size, spatial_dims)\n",
        "        conv1_stride = ensure_tuple_rep(conv1_t_stride, spatial_dims)\n",
        "\n",
        "        self.conv1 = conv_type(\n",
        "            n_input_channels,\n",
        "            self.in_planes,\n",
        "            kernel_size=conv1_kernel_size,  # type: ignore\n",
        "            stride=conv1_stride,  # type: ignore\n",
        "            padding=tuple(k // 2 for k in conv1_kernel_size),  # type: ignore\n",
        "            bias=False,\n",
        "        )\n",
        "        self.bn1 = norm_type(self.in_planes)\n",
        "        self.relu = nn.ReLU(inplace=inplace)\n",
        "        self.maxpool = pool_type(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, block_inplanes[0], layers[0], spatial_dims, shortcut_type)\n",
        "        self.layer2 = self._make_layer(block, block_inplanes[1], layers[1], spatial_dims, shortcut_type, stride=2)\n",
        "        self.layer3 = self._make_layer(block, block_inplanes[2], layers[2], spatial_dims, shortcut_type, stride=2)\n",
        "        self.layer4 = self._make_layer(block, block_inplanes[3], layers[3], spatial_dims, shortcut_type, stride=2)\n",
        "        self.avgpool = avgp_type(block_avgpool[spatial_dims])\n",
        "        self.fc = nn.Linear(block_inplanes[3] * block.expansion, num_classes) if feed_forward else None\n",
        "        self.relu2 = nn.ReLU(inplace=inplace)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, conv_type):\n",
        "                nn.init.kaiming_normal_(torch.as_tensor(m.weight), mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            elif isinstance(m, norm_type):\n",
        "                nn.init.constant_(torch.as_tensor(m.weight), 1)\n",
        "                nn.init.constant_(torch.as_tensor(m.bias), 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.constant_(torch.as_tensor(m.bias), 0)\n",
        "\n",
        "     def _downsample_basic_block(self, x: torch.Tensor, planes: int, stride: int, spatial_dims: int = 3) -> torch.Tensor:\n",
        "        out: torch.Tensor = get_pool_layer((\"avg\", {\"kernel_size\": 1, \"stride\": stride}), spatial_dims=spatial_dims)(x)\n",
        "        zero_pads = torch.zeros(out.size(0), planes - out.size(1), *out.shape[2:], dtype=out.dtype, device=out.device)\n",
        "        out = torch.cat([out.data, zero_pads], dim=1)\n",
        "        return out\n",
        "\n",
        "     def _make_layer(\n",
        "        self,\n",
        "        block: type[Union[ResNetBlock , ResNetBottleneck]],\n",
        "        planes: int,\n",
        "        blocks: int,\n",
        "        spatial_dims: int,\n",
        "        shortcut_type: str,\n",
        "        stride: int = 1,\n",
        "    ) -> nn.Sequential:\n",
        "        conv_type: Callable = Conv[Conv.CONV, spatial_dims]\n",
        "        norm_type: Callable = Norm[Norm.BATCH, spatial_dims]\n",
        "\n",
        "        downsample: Union(nn.Module , partial) = None\n",
        "        if stride != 1 or self.in_planes != planes * block.expansion:\n",
        "            if look_up_option(shortcut_type, {\"A\", \"B\"}) == \"A\":\n",
        "                downsample = partial(\n",
        "                    self._downsample_basic_block,\n",
        "                    planes=planes * block.expansion,\n",
        "                    stride=stride,\n",
        "                    spatial_dims=spatial_dims,\n",
        "                )\n",
        "            else:\n",
        "                downsample = nn.Sequential(\n",
        "                    conv_type(\n",
        "                        self.in_planes,\n",
        "                        planes * block.expansion,\n",
        "                        kernel_size=1,\n",
        "                        stride=stride,\n",
        "                        bias=self.bias_downsample,\n",
        "                    ),\n",
        "                    norm_type(planes * block.expansion),\n",
        "                )\n",
        "        layers = [block(in_planes=self.in_planes, planes=planes, spatial_dims=spatial_dims, stride=stride, inplace=self.inplace, downsample=downsample)]\n",
        "        self.in_planes = planes * block.expansion\n",
        "        for _i in range(0, blocks):\n",
        "            layers.append(block(self.in_planes, planes, spatial_dims=spatial_dims,inplace=self.inplace))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "     def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        if not self.no_max_pool:\n",
        "            x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        if self.fc is not None:\n",
        "            x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "def _resnet(\n",
        "    arch: str,\n",
        "    block: type[Union[ResNetBlock , ResNetBottleneck]],\n",
        "    layers: list[int],\n",
        "    block_inplanes: list[int],\n",
        "    pretrained: bool,\n",
        "    progress: bool,\n",
        "    inplace=True,\n",
        "    **kwargs: Any,\n",
        ") -> ResNet:\n",
        "  #  print('the block is: ',block)\n",
        "    model: ResNet = ResNet(block, layers, block_inplanes, inplace=inplace, **kwargs)\n",
        "    if pretrained:\n",
        "        # Author of paper zipped the state_dict on googledrive,\n",
        "        # so would need to download, unzip and read (2.8gb file for a ~150mb state dict).\n",
        "        # Would like to load dict from url but need somewhere to save the state dicts.\n",
        "        raise NotImplementedError(\n",
        "            \"Currently not implemented. You need to manually download weights provided by the paper's author\"\n",
        "            \" and load then to the model with `state_dict`. See https://github.com/Tencent/MedicalNet\"\n",
        "            \"Please ensure you pass the appropriate `shortcut_type` and `bias_downsample` args. as specified\"\n",
        "            \"here: https://github.com/Tencent/MedicalNet/tree/18c8bb6cd564eb1b964bffef1f4c2283f1ae6e7b#update20190730\"\n",
        "        )\n",
        "    return model\n",
        "def resnet18(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
        "    \"\"\"ResNet-18 with optional pretrained support when `spatial_dims` is 3.\n",
        "\n",
        "    Pretraining from `Med3D: Transfer Learning for 3D Medical Image Analysis <https://arxiv.org/pdf/1904.00625.pdf>`_.\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on 23 medical datasets\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet(\"resnet18\", ResNetBlock, [2, 2, 2, 2], get_inplanes(), pretrained, progress, **kwargs)\n"
      ],
      "metadata": {
        "id": "W3BGv86la2g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "LvdmM-_evbpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Author: Michail Mamalakis\n",
        "#Version: 0.1\n",
        "#Licence:MIT\n",
        "#email:mm2703@cam.ac.uk\n",
        "\n",
        "#an extention including Resnet3DBuilder from https://github.com/JihongJu/keras-resnet3d\n",
        "# pip install git+https://github.com/JihongJu/keras-resnet3d.git\n",
        "\n",
        "from __future__ import division, print_function\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import  MaxPooling1D, Lambda, MultiHeadAttention, Input, Conv2D, Concatenate, MaxPooling2D, AveragePooling2D, AveragePooling1D, Dense, Flatten, Reshape, Activation, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "# name of weights store of main segmentation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "class create_3Dnet:\n",
        "\n",
        "\tdef __init__(self, model,height,width,depth,channels,classes,name=\"\",do=0.3, path=\"/home/mm2703/code/s3D/test/\",backbone=\"simple_3d\",paral='off',b_w='simple_3d_gpu_L_skeleton_3d_image_classification.h5'):\n",
        "\t\tself.model=model\n",
        "\t\tself.height=height\n",
        "\t\tself.width=width\n",
        "\t\tself.depth=depth\n",
        "\t\tself.channels=channels\n",
        "\t\tself.classes=classes\n",
        "\t\tself.path=path\n",
        "\t\tself.name=name\n",
        "\t\tself.do=do\n",
        "\t\tself.backbone=backbone\n",
        "\t\tself.backb_w=b_w\n",
        "\t\tself.par=paral\n",
        "\tdef model_builder(self):\n",
        "\t\tif self.model==\"simple_3d\":\n",
        "\t\t\tinit_model=self.simple_3d()\n",
        "\t\t\tmodel=self.MLP(init_model)\n",
        "\t\telif self.model=='simple_MHL':\n",
        "\t\t\tinit_model=self.tune_MHL(backbone=self.backbone,name=self.name,store_model=self.path,parallel=self.par)\n",
        "\n",
        "\t\t\tmodel_file=str(self.path + \"/\"+self.backb_w)\n",
        "\t\t\tif os.path.exists(model_file):\n",
        "\t\t\t\tprint(model_file)\n",
        "\t\t\t\tinit_model.load_weights(model_file,by_name=True, skip_mismatch=True)\n",
        "\t\t\tmodel=self.MLP(init_model)\n",
        "\t\telif self.model=='double_3d':\n",
        "\t\t\tinit_model=self.double_3d()\n",
        "\t\t\tmodel=self.MLP(init_model)\n",
        "\t\telse:\n",
        "\t\t\tprint(\"no model is given\")\n",
        "\t\treturn model\n",
        "\n",
        "\n",
        "\tdef simple_3d(self,backbone_use='off'):\n",
        "\t\t\"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
        "\n",
        "\t\tinputs = keras.Input((self.width, self.height, self.depth, 1))\n",
        "\n",
        "\t\tx = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
        "\t\tx = layers.MaxPool3D(pool_size=2)(x)\n",
        "\t\t#x = layers.BatchNormalization()(x)\n",
        "\n",
        "\t\tx = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "\t\tx = layers.MaxPool3D(pool_size=2)(x)\n",
        "\t\t#x = layers.BatchNormalization()(x)\n",
        "\n",
        "\t\tx = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "\t\tx = layers.MaxPool3D(pool_size=2)(x)\n",
        "\t\t#x = layers.BatchNormalization()(x)\n",
        "\n",
        "\t\tx = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "\t\tx = layers.MaxPool3D(pool_size=2)(x)\n",
        "\t\t#x = layers.BatchNormalization()(x)\n",
        "\n",
        "\t\tx = layers.GlobalAveragePooling3D()(x)\n",
        "\t\tx = layers.Dense(units=512, activation=\"relu\")(x)\n",
        "\t\tx = layers.Dropout(self.do)(x)\n",
        "\t\tif backbone_use=='off':\n",
        "\t\t\toutputs = layers.Dense(units=1024, activation=\"softmax\")(x)\n",
        "\t\telse:\n",
        "\t\t\toutputs = layers.Dense(units=15376, activation=\"softmax\")(x)\n",
        "\t\t# Define the model.\n",
        "\t\tmodel = Model(inputs, outputs, name=\"3dcnn\")\n",
        "\t\treturn model\n",
        "\n",
        "\n",
        "\tdef double_3d(self):\n",
        "\n",
        "\t\tinputs1 = keras.Input((self.width, self.height, self.depth, 1))\n",
        "\t\tinputs2 = keras.Input((self.width, self.height, self.depth, 1))\n",
        "\n",
        "\t\tx = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs1)\n",
        "\t\tx1 = layers.MaxPool3D(pool_size=2)(x)\n",
        "\t\t#x = layers.BatchNormalization()(x)\n",
        "\n",
        "\t\tx = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x1)\n",
        "\t\tx2 = layers.MaxPool3D(pool_size=2)(x)\n",
        "\t\t#x = layers.BatchNormalization()(x)\n",
        "\n",
        "\t\tx = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x2)\n",
        "\t\tx3 = layers.MaxPool3D(pool_size=2)(x)\n",
        "\t\t#x = layers.BatchNormalization()(x)\n",
        "\n",
        "\t\tx = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x3)\n",
        "\t\tx4 = layers.MaxPool3D(pool_size=2)(x)\n",
        "\t\t#x = layers.BatchNormalization()(x)\n",
        "\n",
        "\t\tx = layers.GlobalAveragePooling3D()(x4)\n",
        "\t\tx = layers.Dense(units=512, activation=\"relu\")(x)\n",
        "\t\tx5 = layers.Dropout(self.do)(x)\n",
        "\n",
        "\n",
        "\t\ty = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs2)\n",
        "\t\ty1 = layers.MaxPool3D(pool_size=2)(y)\n",
        "                #x = layers.BatchNormalization()(x)\n",
        "\t\ty = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(y1)\n",
        "\t\ty2 = layers.MaxPool3D(pool_size=2)(y)\n",
        "                #x = layers.BatchNormalization()(x)\n",
        "\n",
        "\t\ty = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(y2)\n",
        "\t\ty3 = layers.MaxPool3D(pool_size=2)(y)\n",
        "                #x = layers.BatchNormalization()(x)\n",
        "\n",
        "\t\ty = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(y3)\n",
        "\t\ty4 = layers.MaxPool3D(pool_size=2)(y)\n",
        "                #x = layers.BatchNormalization()(x)\n",
        "\n",
        "\t\ty = layers.GlobalAveragePooling3D()(y4)\n",
        "\t\ty = layers.Dense(units=512, activation=\"relu\")(y)\n",
        "\t\ty5 = layers.Dropout(self.do)(y)\n",
        "\n",
        "\t\tRx1=layers.Flatten(name='flatten_tunedRx1')(x1)\n",
        "\t\tRy1=layers.Flatten(name='flatten_tunedRy1')(y1)\n",
        "\t\tR1=layers.MultiHeadAttention(num_heads=2,key_dim=self.height,attention_axes=(1))(Rx1,Ry1)\n",
        "\n",
        "\t\tRx2=layers.Flatten(name='flatten_tunedRx2')(x2)\n",
        "\t\tRy2=layers.Flatten(name='flatten_tunedRy2')(y2)\n",
        "\t\tR2=layers.MultiHeadAttention(num_heads=2,key_dim=self.height,attention_axes=(1))(Rx2,Ry2)\n",
        "\n",
        "\t\tRx3=layers.Flatten(name='flatten_tunedRx3')(x3)\n",
        "\t\tRy3=layers.Flatten(name='flatten_tunedRy3')(y3)\n",
        "\t\tR3=layers.MultiHeadAttention(num_heads=2,key_dim=self.height,attention_axes=(1))(Rx3,Ry3)\n",
        "\n",
        "\n",
        "\t\tRx4=layers.Flatten(name='flatten_tunedRx4')(x4)\n",
        "\t\tRy4=layers.Flatten(name='flatten_tunedRy4')(y4)\n",
        "\t\tR4=layers.MultiHeadAttention(num_heads=2,key_dim=self.height,attention_axes=(1))(Rx4,Ry4)\n",
        "\n",
        "\t\tR=layers.Concatenate()([R1,R2,R3,R4])\n",
        "\t\tprint(R.shape)\n",
        "\t\tR=tf.reshape(R, [1, 158898176, 1])\n",
        "\t\trg1=layers.MaxPooling1D(pool_size=64)(R)\n",
        "\t\trg1f=layers.Flatten(name='flatten_rg1')(rg1)\n",
        "\t\trg = layers.Dense(units=(4096), activation=\"relu\")(rg1f)\n",
        "\t\tprint(rg.shape)\n",
        "\t\treturn Model(inputs=[inputs1,inputs2],outputs=rg,name=\"double_3D\")\n",
        "\n",
        "\n",
        "\tdef tune_MHL(self,backbone=\"none\",name=\"\",attention=\"_3d_image_classification\",store_model=\"\",parallel='off'):\n",
        "\t\tinputs=keras.Input((self.width,self.height,self.depth,1))\n",
        "\t\tif backbone==\"none\":\n",
        "\t\t\tx = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
        "\t\t\tx = layers.MaxPool3D(pool_size=2)(x)\n",
        "\t\t\tx = layers.BatchNormalization()(x)\n",
        "\n",
        "\t\t\tx = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "\t\t\tx = layers.MaxPool3D(pool_size=2)(x)\n",
        "\t\t\tx = layers.BatchNormalization()(x)\n",
        "\t\t\tprint(\"case M-Head attention MHL \")\n",
        "\t\t\tx = layers.GlobalAveragePooling3D()(x)\n",
        "\t\t\trc = layers.Dense(units=(self.height*self.width), activation=\"relu\")(x)\n",
        "\n",
        "\t\telif backbone==\"simple_3d_tune\":\n",
        "\t\t\tSmodel=self.simple_3d('on')\n",
        "\t\t\tmodel_file=str(store_model + \"/\"+self.backb_w)\n",
        "\t\t\tprint(model_file)\n",
        "\t\t\tif os.path.exists(model_file):\n",
        "\t\t\t\tSmodel.load_weights(model_file,by_name=True, skip_mismatch=True)\n",
        "\t\t\t\tprint('load denset weights')\n",
        "\t\t\trc=Smodel(inputs)\n",
        "\t\t\t#Rc=Smodel.output\n",
        "\n",
        "\t\telif backbone==\"simple_3d\":\n",
        "\t\t\tx = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
        "\t\t\tx = layers.MaxPool3D(pool_size=2)(x)\n",
        "\t\t\tx = layers.BatchNormalization()(x)\n",
        "\n",
        "\t\t\tx = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "\t\t\tx = layers.MaxPool3D(pool_size=2)(x)\n",
        "\t\t\tx = layers.BatchNormalization()(x)\n",
        "\n",
        "\t\t\tx = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "\t\t\tx = layers.MaxPool3D(pool_size=2)(x)\n",
        "\t\t\trc1 = layers.BatchNormalization()(x)\n",
        "\n",
        "\t\t\tx = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "\t\t\tx = layers.MaxPool3D(pool_size=2)(x)\n",
        "\t\t\trc2 = layers.BatchNormalization()(x)\n",
        "\n",
        "\t\t\tx = layers.GlobalAveragePooling3D()(x)\n",
        "\t\t\tx = layers.Dense(units=512, activation=\"relu\")(x)\n",
        "\t\t\trc = layers.Dense(units=(15376), activation=\"relu\")(x)\n",
        "\t\t\tprint(\"case M-Head attention simple model \")\n",
        "\t\telse:\n",
        "\t\t\tprint(\"No none backbone network try resnet50, densenet121, or none!\")\n",
        "\t\tRdo=layers.Flatten(name='flatten_tunedR')(rc)\n",
        "\t\tif parallel=='on':\n",
        "\t\t\tRd1=layers.Flatten(name='flatten_tunedR1')(rc1)\n",
        "\t\t\tRd2=layers.Flatten(name='flatten_tunedR2')(rc2)\n",
        "\t\t\tR=layers.MultiHeadAttention(num_heads=3,key_dim=self.height,attention_axes=(1))(Rd1,Rd2,Rdo)\n",
        "\t\t\tRd=R\n",
        "\t\telse:\n",
        "\t\t\tRd=Rdo\n",
        "\t\txrgb=layers.MultiHeadAttention(num_heads=2,key_dim=self.height,attention_axes=(1))(Rd,Rd)\n",
        "\t\tprint(xrgb.shape)\n",
        "\t\tf=layers.Flatten(name='flatten_R')(xrgb)\n",
        "\t\trgb = layers.Dense(units=(15376), activation=\"relu\")(f)\n",
        "\t\tif parallel=='on':\n",
        "\t\t\trgb1=layers.Reshape([124,124,1,1])(rgb)\n",
        "\t\t\trgb2=layers.Reshape([124,124,1,1])(rc)\n",
        "\t\t\trgbc=layers.Concatenate(axis=3)([rgb1,rgb2])\n",
        "\t\t\tr=layers.Reshape([124,124,2,1])(rgbc)\n",
        "\t\t\trgbo = layers.MaxPool3D(pool_size=(1,1,2))(r)\n",
        "\t\telse:\n",
        "\t\t\trgbo=rgb\n",
        "\t\trgb11=layers.Reshape([124,124,1,1])(rgbo)\n",
        "\t\tRCC=layers.Conv3D(filters=self.depth, kernel_size=1, activation=\"relu\")(rgb11)\n",
        "\t\trgx=layers.Reshape([124,124,self.depth,1])(RCC)\n",
        "\t\tx = layers.GlobalAveragePooling3D()(rgx)\n",
        "\t\tRdx=layers.Flatten(name='flatten_tunedRx')(x)\n",
        "\t\trg = layers.Dense(units=1024, activation=\"relu\")(Rdx)\n",
        "\t\treturn Model(inputs, rg,name=\"3dmhl\")\n",
        "\n",
        "\n",
        "\tdef MLP(self,pretrained_model):\n",
        "\n",
        "\t\tnew_DL=pretrained_model.output\n",
        "\t\tnew_DL=layers.Flatten()(new_DL)\n",
        "\t\tnew_DL=layers.Dense(1024, activation=\"relu\")(new_DL)   #64\n",
        "\t\tnew_DL=layers.Dropout(self.do)(new_DL)\n",
        "\t\tnew_DL=layers.Dense(512, activation=\"relu\")(new_DL)    #64\n",
        "\t\tnew_DL=layers.Dropout(self.do)(new_DL)\n",
        "\t\tnew_DL=layers.Dense(self.classes, activation=\"softmax\")(new_DL) #2\n",
        "\t\treturn Model(inputs=pretrained_model.input, outputs=new_DL)"
      ],
      "metadata": {
        "id": "cv9vICJtuXej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "case_ex='.nii'\n",
        "store='XAI_simple/total/sf/R/nPCS_total'\n",
        "path='XAI_simple/total/sf/R/nPCS'\n",
        "comb=2\n",
        "list2=[0.85,0.1,0.5]\n",
        "zoom='off'\n",
        "process_scan(path,store,case_ex,comb,zoom,list2)\n",
        "\n",
        "#XAI_simple/total/sk/L/PCS *black petrubation\n",
        "#XAI_simple/total/sf/L/PCS\n",
        "#XAI_simple/total/sk/R/PCS *mean petrubation\n",
        "#XAI_simple/total/sf/R/PCS *black petrubation"
      ],
      "metadata": {
        "id": "ApjrIt0UQNkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import monai\n",
        "import torch\n",
        "\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n=1\n",
        "expl='XAI_simple/total/sf/R/nPCS_totaltotal_.nii'\n",
        "#expl='XAI_simple/total/sf/R/nPCS2total_GradCam.nii' #(1 is shap)\n",
        "input='XAI_simple/total/sf/R/nPCS0total_shape.nii'\n",
        "#PATH='QCNN/resnet18_L_no_norm_crop_resize'\n",
        "weight_file=(\"simple3D/simple_3dRsf_simple3d_new_data_3d_image_classification.h5\")\n",
        "x=255*normalize(read_nifti_file(input))\n",
        "a=255*normalize(read_nifti_file(expl))\n",
        "print(a.max())\n",
        "y=np.ones(n,dtype=int) #np.zeros(n), np.ones(n)\n",
        "#checkpoint = torch.load(PATH+\".pt\",map_location=torch.device(device))\n",
        "cn=create_3Dnet('simple_3d',184,184,64,1,2,name=\"\",do=0.3,backbone='none',paral='off')\n",
        "model_3=cn.model_builder()\n",
        "model_3.load_weights(weight_file,by_name=True)\n",
        "net=model_3\n",
        "#net=resnet18(spatial_dims=3,n_input_channels=1,num_classes=2).to(device)\n",
        "print(a.shape)\n",
        "a=np.resize(a,[64,184,184,1])\n",
        "x=np.resize(x,[64,184,184,1])\n",
        "a=np.expand_dims(a, axis=0)\n",
        "x=np.expand_dims(x, axis=0)\n",
        "#net.load_state_dict(checkpoint['model_state_dict'])\n",
        "y_=y[:].reshape(n,1)\n",
        "x_=x.transpose(0,4,3,2,1)\n",
        "x_1=x.transpose(0,3,2,1,4)\n",
        "a_=a.transpose(0,4,3,2,1)#.detach().cpu().numpy()\n",
        "a_1=a.transpose(0,3,2,1,4)#.detach().cpu().numpy()\n",
        "x_11=(x_1)#.detach().cpu().numpy()\n",
        "y_o=(y_)#.detach().cpu().numpy()\n",
        "#net.eval()\n",
        "#net.to(device)\n",
        "rc=quantus.Complexity(disable_warnings=True)(model=net, x_batch=x_,y_batch=y_,a_batch=a_,device=device,channel_first=True)\n",
        "print(rc)\n",
        "\n",
        "rd=quantus.FaithfulnessCorrelation(nr_runs=100,  subset_size=4000,  perturb_baseline=\"black\", perturb_func=quantus.perturb_func.baseline_replacement_by_indices,similarity_func=quantus.similarity_func.correlation_pearson,  abs=True, return_aggregate=False, disable_warnings = True)(model=net,x_batch=x_11, y_batch=y_o,a_batch=a_1,channel_first=True,device=device)\n",
        "print(rd)"
      ],
      "metadata": {
        "id": "gXIainn-L0JG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuClass": "premium",
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}